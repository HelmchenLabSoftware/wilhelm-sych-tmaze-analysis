{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "* Spike frequency\n",
    "    * by channel\n",
    "    * by phase/interval (individual cells and grand average)\n",
    "    * Discriminate LR/CM\n",
    "* Smooth correlation (use gaussian filter to account for +/- a few timesteps)\n",
    "* Plot average firing probability for each cell vs time\n",
    "* Confusion-matrix based predictor for sequences\n",
    "\n",
    "**Questions**:\n",
    "* What to do with spike probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "from copy import deepcopy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Append base directory\n",
    "import os,sys,inspect\n",
    "rootname = \"chernysheva-tmaze-analysis-2020\"\n",
    "thispath = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "rootpath = os.path.join(thispath[:thispath.index(rootname)], rootname)\n",
    "sys.path.append(rootpath)\n",
    "print(\"Appended root directory\", rootpath)\n",
    "\n",
    "# User libraries\n",
    "from mesostat.utils.qt_helper import gui_fname, gui_fnames, gui_fpath\n",
    "\n",
    "# Local libraries\n",
    "from src.lib.data_db import BehaviouralNeuronalDatabase\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_path = root_path_data if 'root_path_data' in locals() else \"./\"\n",
    "params = {}\n",
    "#params['root_path_data']  = gui_fpath(\"Path to data files\", \"./\")\n",
    "params['root_path_dff'] = '/media/alyosha/Data/TE_data/mariadata/dff/'\n",
    "params['root_path_deconv'] = '/media/alyosha/Data/TE_data/mariadata/deconv/'\n",
    "#params['root_path_data'] = '/media/alyosha/Data/TE_data/mariadata/postselect/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB = BehaviouralNeuronalDatabase(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB.read_neuro_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDB.read_behavior_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure()\n",
    "plt.plot(dataDB.dataNeuronal['deconv'][0][:, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Firing rate by cell\n",
    "FPS = 10 #Hz\n",
    "np.nanmean(dataDB.dataNeuronal['deconv'][0][:, 0])* FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def H(x):\n",
    "    return np.sum(-x*np.log2(x))\n",
    "\n",
    "def MI(M):\n",
    "    pA = np.sum(M, axis=0)\n",
    "    pB = np.sum(M, axis=1)\n",
    "    return H(pA) + H(pB) - H(M.flatten())\n",
    "    \n",
    "\n",
    "nTimes = 10000\n",
    "pA = 0.3\n",
    "pB = 0.1\n",
    "\n",
    "trueMat = np.array([[pA*pB, pA*(1-pB)], [(1-pA)*pB, (1-pA)*(1-pB)]])\n",
    "\n",
    "dataA = np.random.uniform(0, 1, nTimes) < pA\n",
    "dataB = np.random.uniform(0, 1, nTimes) < pB\n",
    "\n",
    "expMat = np.array([\n",
    "    [np.sum(dataA & dataB), np.sum(dataA & (~dataB))],\n",
    "    [np.sum((~dataA) & dataB), np.sum((~dataA) & (~dataB))]\n",
    "]) / nTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H(np.array([pB, 1-pB]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nest)",
   "language": "python",
   "name": "py36nest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
