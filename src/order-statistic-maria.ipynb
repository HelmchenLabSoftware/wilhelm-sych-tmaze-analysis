{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matlab_lib import loadmat\n",
    "import scipy.spatial.distance as ssd\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "def metric(t1, t2):\n",
    "    ord12 = (t1 < t2).astype(float)\n",
    "    return np.abs(2*np.mean(ord12) - 1)\n",
    "\n",
    "def empirical_bounds(data, p):\n",
    "    dataSorted = np.sort(data)\n",
    "    nData = len(data)\n",
    "    nBound = int(p*nData)\n",
    "    return dataSorted[nBound], dataSorted[-nBound]\n",
    "\n",
    "# Convert data to probability distribution\n",
    "def rescale(x, p):\n",
    "    #xnorm = x - np.min(x)         # Subtract minimum\n",
    "    xnorm = x - np.percentile(x, p)  # Subtract percentile to arrive at baseline\n",
    "    xnorm[xnorm < 0] = 0\n",
    "    return xnorm / np.sum(xnorm)  # Normalize\n",
    "\n",
    "# Cycle data backwards by n steps\n",
    "def cycle_data(x, n):\n",
    "    return np.hstack((x[n:], x[:n]))\n",
    "\n",
    "def CDF(p):\n",
    "    rez = np.zeros(len(p) + 1)\n",
    "    for i in range(len(p)):\n",
    "        rez[i+1] = rez[i] + p[i]\n",
    "    return rez\n",
    "\n",
    "def order_func(pvec):\n",
    "    nNode = pvec.shape[0]\n",
    "    cdfVec = [CDF(p) for p in pvec]\n",
    "    \n",
    "    ord1D = np.zeros((nNode, nNode))\n",
    "    for i in range(nNode):\n",
    "        for j in range(nNode):\n",
    "            ord1D[i, j] += [np.sum(cdfVec[i] - cdfVec[j]) > 0]\n",
    "    return ord1D\n",
    "\n",
    "# Compute metric from comparisons matrix\n",
    "# Comparisons matrix dimensions [nTrial, nCell, nCell]\n",
    "def order_metric(comparisonsByTrial):\n",
    "    phat = np.mean(comparisonsByTrial, axis=0)\n",
    "    metricByConn = np.abs(2*phat - 1)\n",
    "    metricByConn[np.eye(nCell, dtype=bool)] = 0  # Set diagonal to zero\n",
    "    return metricByConn\n",
    "\n",
    "# Compute clustering given distance matrix and distance threshold\n",
    "def cluster_dist_matrix(M, nCluster):\n",
    "    distTril = np.tril(metricByConn, 1)\n",
    "    linkageMatrix = linkage(distTril, method='weighted', metric='euclidean')\n",
    "    return fcluster(linkageMatrix, nCluster, criterion='maxclust') - 1  # Original numbering starts at 1 for some reason\n",
    "\n",
    "def orderability_plots(metricByConn, thrBi):\n",
    "    metricByConnOffDiag     = metricByConn[~np.eye(nCell, dtype=bool)]\n",
    "    meanMetricByCell        = np.sum(metricByConn, axis=0) / (nCell-1)\n",
    "    meanMetricByCellSorted  = np.sort(meanMetricByCell)\n",
    "    meanMetricByCellSortIdx = np.argsort(meanMetricByCell)\n",
    "    \n",
    "    print(\"Mean order param\", np.mean(metricByConnOffDiag))\n",
    "    print(\"Number above 1%\", np.mean(metricByConnOffDiag > thrBi))\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=4, figsize=(16,4))\n",
    "    fig.suptitle(dataLabel)\n",
    "    ax[0].set_title(\"Orderability by connection\")\n",
    "    ax[0].hist(metricByConnOffDiag, bins='auto')\n",
    "    ax[0].axvline(x = thrBi, linestyle='--', color='y', label='p=1%')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_xlim(0,1)\n",
    "    ax[1].set_title(\"Orderability matrix\")\n",
    "    ax[1].imshow(metricByConn, vmin=0, vmax=1)\n",
    "    ax[2].set_title(\"Mean orderability by cell, sorted\")\n",
    "    ax[2].plot(meanMetricByCellSorted)\n",
    "    ax[3].set_title(\"Orderability matrix, sorted\")\n",
    "    ax[3].imshow(metricByConn[meanMetricByCellSortIdx][:, meanMetricByCellSortIdx], vmin=0, vmax=1)\n",
    "    \n",
    "def clustering_plots(matRescaled, metricByConn, clustering):\n",
    "    nTime = matRescaled.shape[2]\n",
    "    clusterSortIdxs = np.argsort(clustering)  # Node indices so that clusters appear consecutive\n",
    "    nCluster = np.max(clustering)\n",
    "    nodePerClusterCumul = [np.sum(clustering <= j+1) for j in range(nCluster)]\n",
    "\n",
    "    # Plot orderability metric matrix, and cluster separators with red lines\n",
    "    fig2, ax2 = plt.subplots(ncols=2, figsize=(8,4))\n",
    "    ax2[0].imshow(metricByConn[clusterSortIdxs][:, clusterSortIdxs])\n",
    "    for clusterSep in nodePerClusterCumul:\n",
    "        ax2[0].axvline(x = clusterSep-0.5, color='r', alpha=0.5)\n",
    "        ax2[0].axhline(y = clusterSep-0.5, color='r', alpha=0.5)\n",
    "        \n",
    "    # Plot average rescaled activity for each cluster\n",
    "    for iCluster in range(nCluster):\n",
    "        mu = np.mean(matRescaled[clustering == iCluster], axis=(0,1)) * 50 + iCluster\n",
    "        std = np.std(matRescaled[clustering == iCluster], axis=(0,1)) * 50 \n",
    "        ax2[1].fill_between(np.arange(nTime), mu-std, mu+std, alpha=0.3)\n",
    "        ax2[1].plot(mu, label=str(iCluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matDict = {\n",
    "    'left' : loadmat(\"../data/exampledata_left.mat\")['input_field1'],\n",
    "    'right' : loadmat(\"../data/exampledata_right.mat\")['input_field2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(matDict['left'][3,:5].flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Investigate baseline\n",
    "\n",
    "The neuronal baseline will be computed as the n-th lowest percentile. User can validate the baseline selection by observing histograms of a few example cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCell, nTrial, nTime = matDict['left'].shape\n",
    "\n",
    "fig, ax = plt.subplots(ncols = nCell, figsize=(4*nCell, 4))\n",
    "for i in range(nCell):\n",
    "    dataThis = matDict['left'][i].flatten()\n",
    "    cut = np.percentile(dataThis, 30)\n",
    "    ax[i].hist(dataThis, bins='auto')\n",
    "    ax[i].axvline(x=cut, color='y', linestyle='--')\n",
    "    ax[i].set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordering for data\n",
    "\n",
    "1. Subtract minimum and normalize\n",
    "2. Compute CDF\n",
    "3. Subtract CDF and integrate\n",
    "\n",
    "**TODO**:\n",
    "* Try separate cells that are unorderable compared to everything (not sure how)\n",
    "* Try from another period(delay vs action vs ...)\n",
    "* Try predict behaviour (turn left-right) from orderable vs unorderable cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentileBaseline = 30 # Out of 100\n",
    "nClusterAim = [7, 5]            # Determines number of clusters\n",
    "thrBivar = [0.297, 0.322]       # Bivariate order statistic threshold for p=[5%, 1%]\n",
    "thrMulti = [0.12, 0.135]        # Multivariate order statistic threshold for p=[5%, 1%]\n",
    "\n",
    "for iDataSet, (dataLabel, dataMat) in enumerate(matDict.items()):\n",
    "    ###########################\n",
    "    # Sorting\n",
    "    ###########################\n",
    "    \n",
    "    # Rescale original data\n",
    "    matRescaled = np.copy(dataMat)\n",
    "    nCell, nTrial, nTime = matRescaled.shape\n",
    "    print(\"Processing data (nCell, nTrial, nTime) =\", matRescaled.shape)\n",
    "\n",
    "    comparisonsByTrial = np.zeros((nTrial, nCell, nCell))\n",
    "    for iTrial in range(nTrial):\n",
    "        # Rescale all data for this trial\n",
    "        for iCell in range(nCell):\n",
    "            matRescaled[iCell, iTrial] = rescale(matRescaled[iCell, iTrial], percentileBaseline)\n",
    "        comparisonsByTrial[iTrial] = order_func(matRescaled[:, iTrial])\n",
    "\n",
    "    # Compute order metric for every \n",
    "    metricByConn = order_metric(comparisonsByTrial)\n",
    "    \n",
    "    # Make orderability plots\n",
    "    orderability_plots(metricByConn, thrBivar[iDataSet])\n",
    "    \n",
    "    ###########################\n",
    "    # Clustering\n",
    "    ###########################\n",
    "    \n",
    "    # Perform clustering\n",
    "    clustering = cluster_dist_matrix(metricByConn, nClusterAim[iDataSet])  # Cluster index for each node\n",
    "    \n",
    "    # Construct clustering plots\n",
    "    clustering_plots(matRescaled, metricByConn, clustering)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Validation V1\n",
    "\n",
    "Cycle all signals by a random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentileBaseline = 30 # Out of 100\n",
    "thrBivar = [0.297, 0.322]       # Bivariate order statistic threshold for p=[5%, 1%]\n",
    "\n",
    "for iDataSet, (dataLabel, dataMat) in enumerate(matDict.items()):\n",
    "    ###########################\n",
    "    # Sorting\n",
    "    ###########################\n",
    "    \n",
    "    # Rescale original data\n",
    "    matRescaled = np.copy(dataMat)\n",
    "    nCell, nTrial, nTime = matRescaled.shape\n",
    "    print(\"Processing data (nCell, nTrial, nTime) =\", matRescaled.shape)\n",
    "\n",
    "    comparisonsByTrial = np.zeros((nTrial, nCell, nCell))\n",
    "    for iCell in range(nCell):\n",
    "        for iTrial in range(nTrial):    \n",
    "            matRescaled[iCell, iTrial] = rescale(matRescaled[iCell, iTrial], percentileBaseline)\n",
    "            \n",
    "            # Add cycling\n",
    "            nCycle = np.random.randint(0, nTime)\n",
    "            matRescaled[iCell, iTrial] = cycle_data(matRescaled[iCell, iTrial], nCycle)\n",
    "        \n",
    "    for iTrial in range(nTrial):        \n",
    "        comparisonsByTrial[iTrial] = order_func(matRescaled[:, iTrial])\n",
    "\n",
    "    # Compute order metric for every \n",
    "    metricByConn = order_metric(comparisonsByTrial)\n",
    "    \n",
    "    print(\"1% cutoff\", np.percentile(metricByConn[~np.eye(nCell, dtype=bool)], 99))\n",
    "    \n",
    "    # Make orderability plots\n",
    "    orderability_plots(metricByConn, thrBivar[iDataSet])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation 2\n",
    "\n",
    "Shuffle each trial by cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentileBaseline = 30 # Out of 100\n",
    "thrBivar = [0.297, 0.322]       # Bivariate order statistic threshold for p=[5%, 1%]\n",
    "\n",
    "for iDataSet, (dataLabel, dataMat) in enumerate(matDict.items()):\n",
    "    ###########################\n",
    "    # Sorting\n",
    "    ###########################\n",
    "    \n",
    "    # Rescale original data\n",
    "    matRescaled = np.copy(dataMat)\n",
    "    nCell, nTrial, nTime = matRescaled.shape\n",
    "    print(\"Processing data (nCell, nTrial, nTime) =\", matRescaled.shape)\n",
    "\n",
    "    comparisonsByTrial = np.zeros((nTrial, nCell, nCell))\n",
    "    for iTrial in range(nTrial):    \n",
    "        for iCell in range(nCell):\n",
    "            matRescaled[iCell, iTrial] = rescale(matRescaled[iCell, iTrial], percentileBaseline)\n",
    "            \n",
    "        cellPerm = np.random.permutation(nCell)\n",
    "        comparisonsByTrial[iTrial] = order_func(matRescaled[cellPerm, iTrial])\n",
    "\n",
    "    # Compute order metric for every \n",
    "    metricByConn = order_metric(comparisonsByTrial)\n",
    "    \n",
    "    print(\"1% cutoff\", np.percentile(metricByConn[~np.eye(nCell, dtype=bool)], 99))\n",
    "    \n",
    "    # Make orderability plots\n",
    "    orderability_plots(metricByConn, thrBivar[iDataSet])\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36qt5)",
   "language": "python",
   "name": "py36qt5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
